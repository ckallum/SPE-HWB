# Product Evaluation
In order to validate our application meets the client specification, we had to ensure that we iteratively evaluated our application when we released a new version with additional functionalities. To achieve this, we made sure that the app was tested by current students of the university through a questionnaire. To produce a fair evaluation, we decided to question two audiences: students who hold a sports membership and students who don’t. This allowed us to find a general consensus of our solution. We evaluated each release based on ease of use and functionality.

It was important to select an appropriate environment in order to evaluate our application. To target students who hold sports memberships, we believed the Indoor Sports Centre was the most appropriate location. To target non-members, we found users in MVB to test our application. Specifically, we provided an android smartphone which already has the application installed and a questionnaire. We’d allow the user to freely navigate through the application and provide verbal and written feedback via the questionnaire. We aimed to have our implementation tested by at least 15 people (members and non-members).

The questionnaire mainly highlighted aspects such as how easy it is to use/navigate the app, whether the user interface is appealing, whether they’d use the app again, if they liked the implementation, etc.

Using the responses from our questionnaire, we then looked into how we can further improve our application. For example, when we first implemented the user interface, we received a lot of responses that mentioned the colour scheme was a bit too dark and unappealing. We therefore opted for a much more appealing colour scheme. We made sure to have this re-evaluated and the majority of the responses stated the UI was much more appealing with the new colour scheme. When we implemented the events page of the app, a lot of the responses stated that they’d like an option to filter the results. We took this response onboard and implemented a filter for searching events. This resulted in more positive responses.

Upon observation, we also noticed a lot of users were trying to click on the map logo to view the location of that facility. We therefore decided to implement a feature which allows the user to click on a map icon and view where on the map the facility is.

As well as receiving feedback from students, we held regular scheduled meetings with our clients( approx every two weeks, one if convenient ). These meetings mainly consisted of recieving feedback about the application and how we can further improve it. We recorded notes during each meeting in order to keep track of improvements we needed to make, making note of additional tasks in Jira.

In conclusion, it is evident that through observation, consistent client communication/feedback and the use of a questionnaire has allowed our final product to fulfill more of the client and users specifications.

### Questionnaire
Link to Questionnaire: [Questionnaire](Questionnaire/Questionnaire.pdf)
